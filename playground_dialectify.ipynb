{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the sql to encode and decode only some parts of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT name, age, email FROM users\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "# Define the SQL statement\n",
    "sql_statement = \"SELECT name, age, email FROM users\"\n",
    "\n",
    "# Parse the SQL statement using sqlparse\n",
    "parsed_statement = sqlparse.parse(sql_statement)[0]\n",
    "\n",
    "print(parsed_statement)\n",
    "\n",
    "# Extract the field names from the SELECT statement\n",
    "# fields = [str(token) for token in parsed_statement.tokens if token.ttype is sqlparse.tokens.Name]\n",
    "\n",
    "# # Print the field names\n",
    "# print(fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " 'cli',\n",
       " 'engine',\n",
       " 'exceptions',\n",
       " 'filters',\n",
       " 'format',\n",
       " 'formatter',\n",
       " 'keywords',\n",
       " 'lexer',\n",
       " 'parse',\n",
       " 'parsestream',\n",
       " 'split',\n",
       " 'sql',\n",
       " 'tokens',\n",
       " 'utils']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "dir(sqlparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['select * from foo;', 'select * from bar;']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = 'select * from foo; select * from bar;'\n",
    "statements = sqlparse.split(raw)\n",
    "statements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT *\n",
      "FROM foo;\n"
     ]
    }
   ],
   "source": [
    "# Format the first statement and print it out:\n",
    "first = statements[0]\n",
    "print(sqlparse.format(first, reindent=True, keyword_case='upper'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sqlparse' has no attribute 'get_identifiers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m identify \u001b[39m=\u001b[39m sqlparse\u001b[39m.\u001b[39;49mget_identifiers(\u001b[39m'\u001b[39m\u001b[39mselect order.orderid, order.order_name, revenue.order_id, r.product_name, revenue.cost from orders o join revenue r on r.order_id  = r.order_id order by order.orderid desc\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(identify\u001b[39m.\u001b[39mtokens)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sqlparse' has no attribute 'get_identifiers'"
     ]
    }
   ],
   "source": [
    "identify = sqlparse.get_identifiers('select order.orderid, order.order_name, revenue.order_id, r.product_name, revenue.cost from orders o join revenue r on r.order_id  = r.order_id order by order.orderid desc')[0]\n",
    "print(identify.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<DML 'select' at 0x118EAAE60>,\n",
       " <Whitespace ' ' at 0x11990D900>,\n",
       " <IdentifierList 'order....' at 0x119909F50>,\n",
       " <Whitespace ' ' at 0x11990F880>,\n",
       " <Keyword 'from' at 0x11990F8E0>,\n",
       " <Whitespace ' ' at 0x11990F940>,\n",
       " <Identifier 'orders...' at 0x119909CB0>,\n",
       " <Whitespace ' ' at 0x11990FAC0>,\n",
       " <Keyword 'join' at 0x11990FB20>,\n",
       " <Whitespace ' ' at 0x11990FB80>,\n",
       " <Identifier 'revenu...' at 0x119909D90>,\n",
       " <Whitespace ' ' at 0x11990FD00>,\n",
       " <Keyword 'on' at 0x11990FD60>,\n",
       " <Whitespace ' ' at 0x11990FDC0>,\n",
       " <Comparison 'r.orde...' at 0x119909EE0>,\n",
       " <Whitespace ' ' at 0x119934220>,\n",
       " <Keyword 'order ...' at 0x119934280>,\n",
       " <Whitespace ' ' at 0x1199342E0>,\n",
       " <Identifier 'order....' at 0x119909E70>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed = sqlparse.parse('select order.orderid, order.order_name, revenue.order_id, r.product_name, revenue.cost from orders o join revenue r on r.order_id  = r.order_id order by order.orderid desc')[0]\n",
    "parsed.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token 0: select\n",
      "Token 1:  \n",
      "Token 2: order.orderid, order.order_name, revenue.order_id, r.product_name, revenue.cost\n",
      "Token 3:  \n",
      "Token 4: from\n",
      "Token 5:  \n",
      "Token 6: orders o\n",
      "Token 7:  \n",
      "Token 8: join\n",
      "Token 9:  \n",
      "Token 10: revenue r\n",
      "Token 11:  \n",
      "Token 12: on\n",
      "Token 13:  \n",
      "Token 14: r.order_id  = r.order_id\n",
      "Token 15:  \n",
      "Token 16: order by\n",
      "Token 17:  \n",
      "Token 18: order.orderid desc\n"
     ]
    }
   ],
   "source": [
    "# Parsing a SQL statement:\n",
    "parsed = sqlparse.parse('select order.orderid, order.order_name, revenue.order_id, r.product_name, revenue.cost from orders o join revenue r on r.order_id  = r.order_id order by order.orderid desc')[0]\n",
    "parsed_tokens = parsed.tokens\n",
    "for i, token in enumerate(parsed_tokens):\n",
    "    print(f\"Token {i}: {token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 14\n",
      "IdentifierList: 1\n",
      "Identifier: 3\n",
      "Comparison: 1\n"
     ]
    }
   ],
   "source": [
    "parsed_tokens = parsed.tokens\n",
    "token_counts = {}\n",
    "\n",
    "for i, token in enumerate(parsed_tokens):\n",
    "    tok_type = type(token).__name__\n",
    "    if tok_type in token_counts:\n",
    "        token_counts[tok_type] += 1\n",
    "    else:\n",
    "        token_counts[tok_type] = 1\n",
    "\n",
    "for tok_type, count in token_counts.items():\n",
    "    print(f\"{tok_type}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rewrite above function but return a list of fields per type in a data table\n",
    "def get_fields(parsed):\n",
    "    parsed_tokens = parsed.tokens\n",
    "    token_counts = {}\n",
    "    for i, token in enumerate(parsed_tokens):\n",
    "        tok_type = type(token).__name__\n",
    "        if tok_type in token_counts:\n",
    "            token_counts[tok_type].append(token)\n",
    "        else:\n",
    "            token_counts[tok_type] = [token]\n",
    "    #return a dictionary of types and their corresponding tokens in a data table\n",
    "    return token_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fields(parsed):\n",
    "    parsed_tokens = parsed.tokens\n",
    "    token_counts = {}\n",
    "    for i, token in enumerate(parsed_tokens):\n",
    "        tok_type = type(token).__name__\n",
    "        if tok_type == 'Whitespace' or tok_type == 'Keyword':\n",
    "            continue\n",
    "        if tok_type in token_counts:\n",
    "            token_counts[tok_type].append(str(token))\n",
    "        else:\n",
    "            token_counts[tok_type] = [str(token)]\n",
    "    #return a list of fields per type in a data table\n",
    "    return token_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: ['SELECT', ' ', ' ', 'FROM', ' ', ' ']\n",
      "IdentifierList: ['first_name, last_name']\n",
      "Identifier: ['employees']\n",
      "Where: ['WHERE salary > 50000']\n"
     ]
    }
   ],
   "source": [
    "from sqlparse import parse\n",
    "\n",
    "# Example SQL query\n",
    "#query = \"select order.order_id, order.order_name, revenue.order_id, r.product_name, revenue.cost from orders o join revenue r on r.order_id  = r.order_id order by order.orderid desc\"\n",
    "query = \"SELECT first_name, last_name FROM employees WHERE salary > 50000\"\n",
    "\n",
    "# Parse the query into tokens\n",
    "parsed = parse(query)[0]\n",
    "\n",
    "# Get the fields in the parsed query\n",
    "fields = get_fields(parsed)\n",
    "\n",
    "# Print out the types and tokens in the data table\n",
    "for tok_type, tokens in fields.items():\n",
    "    print(f\"{tok_type}: {tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['orders o', 'revenue r', 'order', 'orderid desc']\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "def get_identifiers(parsed):\n",
    "    parsed_tokens = parsed.tokens\n",
    "    identifiers = []\n",
    "    for token in parsed_tokens:\n",
    "        tok_type = type(token).__name__\n",
    "        if tok_type == 'Whitespace':\n",
    "            continue\n",
    "        elif tok_type == 'Keyword':\n",
    "            continue\n",
    "        elif tok_type == 'Identifier':\n",
    "            identifier = str(token)\n",
    "            if '.' in identifier:\n",
    "                identifiers.extend(identifier.split('.'))\n",
    "            else:\n",
    "                identifiers.append(identifier)\n",
    "        elif tok_type == 'Name':\n",
    "            identifiers.append(str(token))\n",
    "    return identifiers\n",
    "\n",
    "#sql = \"SELECT first_name, last_name FROM employees WHERE department='Sales'\"\n",
    "sql = \"select order.order_id, order.order_name, revenue.order_id, r.product_name, revenue.cost from orders o join revenue r on r.order_id  = r.order_id order by order.orderid desc\"\n",
    "\n",
    "parsed = sqlparse.parse(sql)[0]\n",
    "identifiers = get_identifiers(parsed)\n",
    "print(identifiers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identifiers(parsed):\n",
    "    parsed_tokens = parsed.tokens\n",
    "    identifier_list = []\n",
    "    for token in parsed_tokens:\n",
    "        tok_type = type(token).__name__\n",
    "        if tok_type == 'IdentifierList':\n",
    "            for identifier in token.get_identifiers():\n",
    "                if not isinstance(identifier, sqlparse.sql.Identifier):\n",
    "                    continue\n",
    "                identifier_name = identifier.get_name()\n",
    "                if '.' in identifier_name:\n",
    "                    identifier_name = identifier_name.split('.')[1]\n",
    "                identifier_list.append(identifier_name)\n",
    "        elif tok_type == 'Identifier':\n",
    "            identifier_name = token.get_name()\n",
    "            if '.' in identifier_name:\n",
    "                identifier_name = identifier_name.split('.')[1]\n",
    "            identifier_list.append(identifier_name)\n",
    "    return identifier_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['orders o', 'revenue r', 'order', 'orderid desc']\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "def get_identifiers(parsed):\n",
    "    parsed_tokens = parsed.tokens\n",
    "    identifiers = []\n",
    "    for token in parsed_tokens:\n",
    "        tok_type = type(token).__name__\n",
    "        if tok_type == 'Whitespace':\n",
    "            continue\n",
    "        elif tok_type == 'Keyword':\n",
    "            continue\n",
    "        elif tok_type == 'Identifier':\n",
    "            identifier = str(token)\n",
    "            if '.' in identifier:\n",
    "                identifiers.extend(identifier.split('.'))\n",
    "            else:\n",
    "                identifiers.append(identifier)\n",
    "        elif tok_type == 'Name':\n",
    "            identifiers.append(str(token))\n",
    "    return identifiers\n",
    "\n",
    "#sql = \"SELECT first_name, last_name FROM employees WHERE department='Sales'\"\n",
    "sql = \"select order.order_id, order.order_name, revenue.order_id, r.product_name, revenue.cost from orders o join revenue r on r.order_id  = r.order_id order by order.orderid desc\"\n",
    "\n",
    "parsed = sqlparse.parse(sql)[0]\n",
    "identifiers = get_identifiers(parsed)\n",
    "print(identifiers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['orders o', 'revenue r', 'order', 'orderid desc']\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "def get_identifiers(parsed):\n",
    "    parsed_tokens = parsed.tokens\n",
    "    identifiers = []\n",
    "    for token in parsed_tokens:\n",
    "        tok_type = type(token).__name__\n",
    "        if tok_type == 'Whitespace':\n",
    "            continue\n",
    "        elif tok_type == 'Keyword':\n",
    "            continue\n",
    "        elif tok_type == 'Identifier':\n",
    "            identifier = str(token)\n",
    "            if '.' in identifier:\n",
    "                identifiers.extend(identifier.split('.'))\n",
    "            else:\n",
    "                identifiers.append(identifier)\n",
    "        elif tok_type == 'Name':\n",
    "            identifiers.append(str(token))\n",
    "    return identifiers\n",
    "\n",
    "#sql = \"SELECT first_name, last_name FROM employees WHERE department='Sales'\"\n",
    "sql = \"select order.order_id, order.order_name, revenue.order_id, r.product_name, revenue.cost from orders o join revenue r on r.order_id  = r.order_id order by order.orderid desc\"\n",
    "\n",
    "parsed = sqlparse.parse(sql)[0]\n",
    "identifiers = get_identifiers(parsed)\n",
    "print(identifiers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['column1', 'column2', 'table1']\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "sql = \"SELECT column1, column2 FROM table1 WHERE column3 = 'value'\"\n",
    "parsed = sqlparse.parse(sql)[0]\n",
    "\n",
    "identifiers = get_identifiers(parsed)\n",
    "print(identifiers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identifier_list(parsed):\n",
    "    parsed_tokens = parsed.tokens\n",
    "    identifier_list = []\n",
    "    for token in parsed_tokens:\n",
    "        tok_type = type(token).__name__\n",
    "        if tok_type == 'IdentifierList':\n",
    "            for identifier in token.get_identifiers():\n",
    "                if not isinstance(identifier, sqlparse.sql.Identifier):\n",
    "                    continue\n",
    "                identifier_name = identifier.get_name()\n",
    "                if '.' in identifier_name:\n",
    "                    identifier_name = identifier_name.split('.')[1]\n",
    "                identifier_list.append(identifier_name)\n",
    "    return identifier_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['column1', 'column2']\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "sql = \"SELECT column1, column2 FROM table1 WHERE column3 = 'value'\"\n",
    "parsed = sqlparse.parse(sql)[0]\n",
    "\n",
    "identifier_list = get_identifier_list(parsed)\n",
    "print(identifier_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tok_types(parsed):\n",
    "    parsed_tokens = parsed.tokens\n",
    "    tok_types = []\n",
    "    for token in parsed_tokens:\n",
    "        tok_type = type(token).__name__\n",
    "        if tok_type in ['Identifier', 'Comparison', 'IdentifierList', 'Where']:\n",
    "            tok_types.append(tok_type)\n",
    "    return tok_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IdentifierList', 'Identifier', 'Where']\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "query = \"SELECT first_name, last_name FROM employees WHERE salary > 50000\"\n",
    "parsed_query = sqlparse.parse(query)[0]\n",
    "tok_types = get_tok_types(parsed_query)\n",
    "print(tok_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Identifier 'elect ...' at 0x119F04740>,\n",
       " <Whitespace ' ' at 0x11AB80280>,\n",
       " <Integer '10' at 0x11AB801C0>,\n",
       " <Whitespace ' ' at 0x11AB825C0>,\n",
       " <IdentifierList 'getdat...' at 0x11AADB4C0>,\n",
       " <Whitespace ' ' at 0x11AB81900>,\n",
       " <Keyword 'from' at 0x11AB827A0>,\n",
       " <Whitespace ' ' at 0x11AB818A0>,\n",
       " <Identifier 'orders...' at 0x119F04200>,\n",
       " <Whitespace ' ' at 0x11AAB41C0>,\n",
       " <Keyword 'join' at 0x11AAB4040>,\n",
       " <Whitespace ' ' at 0x11AAB46A0>,\n",
       " <Identifier 'revenu...' at 0x119F044A0>,\n",
       " <Whitespace ' ' at 0x11AAB4DC0>,\n",
       " <Keyword 'on' at 0x11AAB4D60>,\n",
       " <Whitespace ' ' at 0x11AAB50C0>,\n",
       " <Comparison 'o.orde...' at 0x11AADB680>]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "query = \"Select top 10 getdate(), order_number, client_name, sum(net_revenue) from orders o join revenue r on o.order_id = r.order_id\"\n",
    "parsed_query = sqlparse.parse(query)[0]\n",
    "parsed_query.tokens\n",
    "#print(parsed_query.tokens)\n",
    "# tok_types = get_identifiers(query)\n",
    "# print(tok_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Token' object has no attribute 'next_token'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[235], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(results) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(tables)\n\u001b[1;32m     34\u001b[0m query \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSelect top 10 getdate(), o.order_number, client_name, sum(r.net_revenue) from orders o join revenue r on o.order_id = r.order_id\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 35\u001b[0m \u001b[39mprint\u001b[39m(extract_columns_and_tables(query))\n",
      "Cell \u001b[0;32mIn[235], line 28\u001b[0m, in \u001b[0;36mextract_columns_and_tables\u001b[0;34m(sql)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[39m# If the token is a join keyword, get the table name from the next token\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[39melif\u001b[39;00m token\u001b[39m.\u001b[39mvalue\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mjoin\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 28\u001b[0m         tables\u001b[39m.\u001b[39madd(token\u001b[39m.\u001b[39;49mnext_token\u001b[39m.\u001b[39mnext_token\u001b[39m.\u001b[39mget_real_name())\n\u001b[1;32m     30\u001b[0m \u001b[39m# Return the list of column and table names\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(results) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(tables)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Token' object has no attribute 'next_token'"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "def extract_columns_and_tables(sql):\n",
    "    # Parse the SQL statement into tokens\n",
    "    parsed = sqlparse.parse(sql)[0]\n",
    "\n",
    "    # Initialize empty lists to store column and table names\n",
    "    results = []\n",
    "    tables = set()\n",
    "\n",
    "    # Loop through all tokens in the parsed SQL statement\n",
    "    for token in parsed.flatten():\n",
    "        # If the token is a function, skip it\n",
    "        if isinstance(token, sqlparse.sql.Function):\n",
    "            continue\n",
    "        # If the token is a column or table name, add it to the results list\n",
    "        elif isinstance(token, sqlparse.sql.Identifier):\n",
    "            # Check if the previous token is a period, indicating a table alias\n",
    "            if token.parent and token.parent.value == '.':\n",
    "                table_name = token.parent.get_previous_sibling().get_real_name()\n",
    "                column_name = token.get_real_name()\n",
    "                results.append(table_name + '.' + column_name)\n",
    "                tables.add(table_name)\n",
    "            else:\n",
    "                results.append(token.get_real_name())\n",
    "        # If the token is a join keyword, get the table name from the next token\n",
    "        elif token.value.lower() == 'join':\n",
    "            tables.add(token.next_token.next_token.get_real_name())\n",
    "\n",
    "    # Return the list of column and table names\n",
    "    return list(results) + list(tables)\n",
    "\n",
    "\n",
    "query = \"Select top 10 getdate(), o.order_number, client_name, sum(r.net_revenue) from orders o join revenue r on o.order_id = r.order_id\"\n",
    "print(extract_columns_and_tables(query))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Token' object has no attribute 'next_token'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[236], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(results) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(tables)\n\u001b[1;32m     34\u001b[0m query \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSelect top 10 getdate(), o.order_number, client_name, sum(r.net_revenue) from orders o join revenue r on o.order_id = r.order_id\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 35\u001b[0m \u001b[39mprint\u001b[39m(extract_columns_and_tables(query))\n",
      "Cell \u001b[0;32mIn[236], line 28\u001b[0m, in \u001b[0;36mextract_columns_and_tables\u001b[0;34m(sql)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[39m# If the token is a join keyword, get the table name from the next token\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[39melif\u001b[39;00m token\u001b[39m.\u001b[39mvalue\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mjoin\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 28\u001b[0m         tables\u001b[39m.\u001b[39madd(token\u001b[39m.\u001b[39;49mnext_token\u001b[39m.\u001b[39mnext_token\u001b[39m.\u001b[39mget_real_name())\n\u001b[1;32m     30\u001b[0m \u001b[39m# Return the list of column and table names\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(results) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(tables)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Token' object has no attribute 'next_token'"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "def extract_columns_and_tables(sql):\n",
    "    # Parse the SQL statement into tokens\n",
    "    parsed = sqlparse.parse(sql)[0]\n",
    "\n",
    "    # Initialize empty lists to store column and table names\n",
    "    results = []\n",
    "    tables = set()\n",
    "\n",
    "    # Loop through all tokens in the parsed SQL statement\n",
    "    for token in parsed.flatten():\n",
    "        # If the token is a function, skip it\n",
    "        if isinstance(token, sqlparse.sql.Function):\n",
    "            continue\n",
    "        # If the token is a column or table name, add it to the results list\n",
    "        elif isinstance(token, sqlparse.sql.Identifier):\n",
    "            # Check if the previous token is a period, indicating a table alias\n",
    "            if token.parent and token.parent.value == '.':\n",
    "                table_name = token.parent.get_previous_sibling().get_real_name()\n",
    "                column_name = token.get_real_name()\n",
    "                results.append(table_name + '.' + column_name)\n",
    "                tables.add(table_name)\n",
    "            else:\n",
    "                results.append(token.get_real_name())\n",
    "        # If the token is a join keyword, get the table name from the next token\n",
    "        elif token.value.lower() == 'join':\n",
    "            tables.add(token.next_token.next_token.get_real_name())\n",
    "\n",
    "    # Return the list of column and table names\n",
    "    return list(results) + list(tables)\n",
    "\n",
    "\n",
    "query = \"Select top 10 getdate(), o.order_number, client_name, sum(r.net_revenue) from orders o join revenue r on o.order_id = r.order_id\"\n",
    "print(extract_columns_and_tables(query))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first_name', 'employees', 'last_name', 'salary', 'department']\n",
      "['first_name', 'employees', 'last_name', 'salary', 'department']\n"
     ]
    }
   ],
   "source": [
    "lst = ['first_name', 'employees', 'last_name', 'salary', 'department']\n",
    "\n",
    "# Mask string literals in the list\n",
    "masked_lst = mask_string_literals(lst)\n",
    "print(masked_lst)  # Output: [\"'first_name'\", 'employees', \"'last_name'\", \"'salary'\", \"'department'\"]\n",
    "\n",
    "# Unmask string literals in the list\n",
    "unmasked_lst = unmask_string_literals(masked_lst)\n",
    "print(unmasked_lst)  # Output: ['first_name', 'employees', 'last_name', 'salary', 'department']\n",
    "\n",
    "# # Apply mask to SQL code\n",
    "# sql = \"SELECT first_name FROM employees WHERE department = 'Sales'\"\n",
    "# masked_sql = apply_mask_to_sql(sql)\n",
    "# print(masked_sql)  # Output: \"SELECT first_name FROM employees WHERE department = ''Sales''\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first_name', 'employees', 'last_name', 'salary', 'department']\n",
      "['first_name', 'employees', 'last_name', 'salary', 'department']\n"
     ]
    }
   ],
   "source": [
    "lst = ['first_name', 'employees', 'last_name', 'salary', 'department']\n",
    "\n",
    "# Mask string literals in the list\n",
    "masked_lst = mask_string_literals(lst)\n",
    "print(masked_lst)  # Output: [\"'first_name'\", 'employees', \"'last_name'\", \"'salary'\", \"'department'\"]\n",
    "\n",
    "# Unmask string literals in the list\n",
    "unmasked_lst = unmask_string_literals(masked_lst)\n",
    "print(unmasked_lst)  # Output: ['first_name', 'employees', 'last_name', 'salary', 'department']\n",
    "\n",
    "# # Apply mask to SQL code\n",
    "# sql = \"SELECT first_name FROM employees WHERE department = 'Sales'\"\n",
    "# masked_sql = apply_mask_to_sql(sql)\n",
    "# print(masked_sql)  # Output: \"SELECT first_name FROM employees WHERE department = ''Sales''\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first_name', 'employees', 'last_name', 'salary', 'department']\n",
      "['first_name', 'employees', 'last_name', 'salary', 'department']\n"
     ]
    }
   ],
   "source": [
    "lst = ['first_name', 'employees', 'last_name', 'salary', 'department']\n",
    "\n",
    "# Mask string literals in the list\n",
    "masked_lst = mask_string_literals(lst)\n",
    "print(masked_lst)  # Output: [\"'first_name'\", 'employees', \"'last_name'\", \"'salary'\", \"'department'\"]\n",
    "\n",
    "# Unmask string literals in the list\n",
    "unmasked_lst = unmask_string_literals(masked_lst)\n",
    "print(unmasked_lst)  # Output: ['first_name', 'employees', 'last_name', 'salary', 'department']\n",
    "\n",
    "# # Apply mask to SQL code\n",
    "# sql = \"SELECT first_name FROM employees WHERE department = 'Sales'\"\n",
    "# masked_sql = apply_mask_to_sql(sql)\n",
    "# print(masked_sql)  # Output: \"SELECT first_name FROM employees WHERE department = ''Sales''\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['order_number', 'o', None, 'sum', 'top', 'client_name', 'r', 'getdate']\n"
     ]
    }
   ],
   "source": [
    "#Alles zusammen - Working for parsing fields from a sql statement. Decide to do it modularly, not sure why but this works. That is why\n",
    "#works for where!!!\n",
    "import sqlparse\n",
    "\n",
    "def get_where_fields(query):\n",
    "    parsed_query = sqlparse.parse(query)[0]\n",
    "    where_clause = None\n",
    "    for token in parsed_query.tokens:\n",
    "        if isinstance(token, sqlparse.sql.Where):\n",
    "            where_clause = token\n",
    "            break\n",
    "    if not where_clause:\n",
    "        return []\n",
    "    fields = []\n",
    "    for token in where_clause.tokens:\n",
    "        if isinstance(token, sqlparse.sql.Comparison):\n",
    "            left = token.left\n",
    "            if isinstance(left, sqlparse.sql.Identifier):\n",
    "                fields.append(left.get_name())\n",
    "            elif isinstance(left, sqlparse.sql.Function):\n",
    "                fields.append(left.tokens[0].get_name())\n",
    "    return fields\n",
    "\n",
    "# Works for identifiers\n",
    "def get_identifiers(query):\n",
    "    parsed_tokens = sqlparse.parse(query)[0]\n",
    "    identifier_set = set()\n",
    "    for token in parsed_tokens:\n",
    "        # If the token is a function, skip it\n",
    "        if isinstance(token, sqlparse.sql.Function):\n",
    "            continue\n",
    "        if isinstance(token, sqlparse.sql.IdentifierList):\n",
    "            for identifier in token.get_identifiers():\n",
    "                identifier_name = identifier.get_name()\n",
    "                if '.' in identifier_name:\n",
    "                    identifier_name = identifier_name.split('.')[1]\n",
    "                identifier_set.add(identifier_name)\n",
    "        elif isinstance(token, sqlparse.sql.Identifier):\n",
    "            identifier_name = token.get_name()\n",
    "            if '.' in identifier_name:\n",
    "                identifier_name = identifier_name.split('.')[1]\n",
    "            identifier_set.add(identifier_name)\n",
    "        elif isinstance(token, sqlparse.sql.Comparison):\n",
    "            identifier_name = token.get_name()\n",
    "            identifier_set.add(identifier_name)\n",
    "        elif isinstance(token, sqlparse.sql.Where):\n",
    "            identifier_name = token.get_name()\n",
    "            identifier_set.add(identifier_name)\n",
    "        elif isinstance(token, sqlparse.sql.Function):\n",
    "            continue\n",
    "    return list(identifier_set)\n",
    "\n",
    "import sqlparse\n",
    "#query = \"SELECT first_name, last_name FROM employees WHERE salary > 50000 AND department = 'Sales'\"\n",
    "query =\"select top 10 getdate(), order_number, client_name, sum(net_revenue) from orders o join revenue r on o.order_id = r.order_id\"\n",
    "identifiers = get_identifiers(query)\n",
    "# where_fields = get_where_fields(query)\n",
    "# list_of_fields = identifiers + where_fields\n",
    "# print(list_of_fields)\n",
    "print(identifiers)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Finally working for this query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['order_number', 'revenue', 'order_id', 'orders', 'client_name']\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "def get_identifiers(sql):\n",
    "    parsed_tokens = sqlparse.parse(sql)[0]\n",
    "    identifier_set = set()\n",
    "    \n",
    "    reserved_words = ['TOP', 'SELECT', 'FROM', 'WHERE', 'JOIN', 'LEFT', 'RIGHT', 'INNER', 'OUTER', 'ON', 'GROUP', 'BY', 'HAVING', 'ORDER', 'ASC', 'DESC']\n",
    "\n",
    "    for token in parsed_tokens.tokens:\n",
    "        # If the token is a function, skip it\n",
    "        if isinstance(token, sqlparse.sql.Function) or token.value.upper() in reserved_words:\n",
    "            continue\n",
    "        if isinstance(token, sqlparse.sql.Function):\n",
    "            continue\n",
    "        if isinstance(token, sqlparse.sql.IdentifierList):\n",
    "            for identifier in token.get_identifiers():\n",
    "                if isinstance(identifier, sqlparse.sql.Identifier):\n",
    "                    identifier_name = identifier.get_real_name()\n",
    "                    if '.' in identifier_name:\n",
    "                        identifier_name = identifier_name.split('.')[1]\n",
    "                    identifier_set.add(identifier_name)\n",
    "        # If the token is a comparison operator, get the column name\n",
    "        elif isinstance(token, sqlparse.sql.Comparison):\n",
    "            identifier_name = token.left.get_real_name()\n",
    "            if '.' in identifier_name:\n",
    "                identifier_name = identifier_name.split('.')[1]\n",
    "            identifier_set.add(identifier_name)\n",
    "        elif isinstance(token, sqlparse.sql.Identifier):\n",
    "            identifier_name = token.get_real_name()\n",
    "            if '.' in identifier_name:\n",
    "                identifier_name = identifier_name.split('.')[1]\n",
    "            identifier_set.add(identifier_name)\n",
    "    return list(identifier_set)\n",
    "\n",
    "\n",
    "\n",
    "query =\"select top 10 getdate(), order_number, client_name, sum(net_revenue) from orders o join revenue r on o.order_id = r.order_id where revenue_order in\"\n",
    "identifiers = get_identifiers(query)\n",
    "print(identifiers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking and Demasking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "def masking(list_of_fields, sql):\n",
    "    \"\"\"\n",
    "    This function takes in a list of words and a SQL string as input and replaces the words in the SQL string with random words.\n",
    "    \"\"\"\n",
    "    # Create a dictionary to store the mapping between original words and masked words\n",
    "    word_map = {}\n",
    "    \n",
    "    # Loop through each word in the list of words\n",
    "    for word in list_of_fields:\n",
    "        # Generate a random word to replace the original word\n",
    "        random_word = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz', k=len(word)))\n",
    "        \n",
    "        # Add the mapping to the dictionary\n",
    "        word_map[word] = random_word\n",
    "        \n",
    "        # Replace the original word with the random word in the SQL string\n",
    "        sql = re.sub(r'\\b{}\\b'.format(word), random_word, sql)\n",
    "    \n",
    "    # Return the masked SQL string and the word map\n",
    "    return sql, word_map\n",
    "\n",
    "\n",
    "def demasking(word_map, sql):\n",
    "    \"\"\"\n",
    "    This function takes in a word map and a masked SQL string as input and replaces the masked words with their original words.\n",
    "    \"\"\"\n",
    "    # Loop through each key-value pair in the word map\n",
    "    for original_word, masked_word in word_map.items():\n",
    "        # Replace the masked word with the original word in the SQL string\n",
    "        sql_string = re.sub(r'\\b{}\\b'.format(masked_word), original_word, sql)\n",
    "    \n",
    "    # Return the demasked SQL string\n",
    "    return sql_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked SQL string: select top 10 getdate(), order_number, client_name, sum(net_revenue) from orders o join revenue r on o.order_id = r.order_id where revenue_order in\n",
      "Word map: {'first_name': 'shyuckvdgw', 'employees': 'uudyfsqyx', 'last_name': 'rvecpyxir', 'salary': 'yqrvxk', 'department': 'uwlebjbjak'}\n",
      "Demasked SQL string: select top 10 getdate(), order_number, client_name, sum(net_revenue) from orders o join revenue r on o.order_id = r.order_id where revenue_order in\n"
     ]
    }
   ],
   "source": [
    "# Define the list of words to mask\n",
    "words_to_mask = ['first_name', 'employees', 'last_name', 'salary', 'department']\n",
    "\n",
    "# Define the SQL string to mask\n",
    "sql = \"SELECT first_name, last_name FROM employees WHERE salary > 50000 AND department = 'Sales'\"\n",
    "\n",
    "# Mask the SQL string\n",
    "masked_sql_string, word_map = masking(words_to_mask, query)\n",
    "\n",
    "# Print the masked SQL string and the word map\n",
    "print(\"Masked SQL string:\", masked_sql_string)\n",
    "print(\"Word map:\", word_map)\n",
    "\n",
    "# Demask the SQL string\n",
    "demasked_sql_string = demasking(word_map, masked_sql_string)\n",
    "\n",
    "# Print the demasked SQL string\n",
    "print(\"Demasked SQL string:\", demasked_sql_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked SQL string: select ciw 10 ufbdnsy(), wjdonbpitghk, ndyykbwdxur, tcv(net_revenue) from orders x join revenue y on x.order_id = y.order_id\n",
      "Word map: {'client_name': 'ndyykbwdxur', 'r': 'y', 'top': 'ciw', 'order_number': 'wjdonbpitghk', 'sum': 'tcv', 'o': 'x', 'getdate': 'ufbdnsy'}\n"
     ]
    }
   ],
   "source": [
    "# Define the list of words to mask\n",
    "words_to_mask = ['client_name', 'r', 'top', 'order_number', 'sum', 'o', 'getdate']\n",
    "\n",
    "# Define the SQL string to mask\n",
    "query = \"select top 10 getdate(), order_number, client_name, sum(net_revenue) from orders o join revenue r on o.order_id = r.order_id\"\n",
    "\n",
    "# Mask the SQL string\n",
    "masked_sql_string, word_map = masking(words_to_mask, query)\n",
    "\n",
    "# Print the masked SQL string and the word map\n",
    "print(\"Masked SQL string:\", masked_sql_string)\n",
    "print(\"Word map:\", word_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['order_number', 'revenue', 'order_id', 'revenue_order', 'orders', 'client_name']\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "def get_identifiers(sql):\n",
    "    parsed_tokens = sqlparse.parse(sql)[0]\n",
    "    identifier_set = set()\n",
    "\n",
    "    reserved_words = ['TOP', 'SELECT', 'FROM', 'WHERE', 'JOIN', 'LEFT', 'RIGHT', 'INNER', 'OUTER', 'ON', 'GROUP', 'BY', 'HAVING', 'ORDER', 'ASC', 'DESC']\n",
    "\n",
    "    def process_identifier(token, identifier_set):\n",
    "        identifier_name = token.get_real_name()\n",
    "        if '.' in identifier_name:\n",
    "            identifier_name = identifier_name.split('.')[1]\n",
    "        identifier_set.add(identifier_name)\n",
    "\n",
    "    def process_function_arguments(token, identifier_set):\n",
    "        if isinstance(token, sqlparse.sql.Identifier):\n",
    "            process_identifier(token, identifier_set)\n",
    "        elif isinstance(token, sqlparse.sql.IdentifierList):\n",
    "            for identifier in token.get_identifiers():\n",
    "                if isinstance(identifier, sqlparse.sql.Identifier):\n",
    "                    process_identifier(identifier, identifier_set)\n",
    "        elif isinstance(token, sqlparse.sql.Parenthesis):\n",
    "            for subtoken in token.tokens:\n",
    "                process_function_arguments(subtoken, identifier_set)\n",
    "\n",
    "    def add_identifiers_from_function(token, identifier_set):\n",
    "        for subtoken in token.tokens:\n",
    "            process_function_arguments(subtoken, identifier_set)\n",
    "\n",
    "    def process_where(token, identifier_set):\n",
    "        for subtoken in token.tokens:\n",
    "            if isinstance(subtoken, sqlparse.sql.Comparison):\n",
    "                process_identifier(subtoken.left, identifier_set)\n",
    "            elif isinstance(subtoken, sqlparse.sql.Identifier):\n",
    "                process_identifier(subtoken, identifier_set)\n",
    "\n",
    "    for token in parsed_tokens.tokens:\n",
    "        if isinstance(token, sqlparse.sql.Function):\n",
    "            add_identifiers_from_function(token, identifier_set)\n",
    "            continue\n",
    "        if token.value.upper() in reserved_words:\n",
    "            continue\n",
    "        if isinstance(token, sqlparse.sql.IdentifierList):\n",
    "            for identifier in token.get_identifiers():\n",
    "                if isinstance(identifier, sqlparse.sql.Identifier):\n",
    "                    process_identifier(identifier, identifier_set)\n",
    "        elif isinstance(token, sqlparse.sql.Comparison):\n",
    "            process_identifier(token.left, identifier_set)\n",
    "        elif isinstance(token, sqlparse.sql.Where):\n",
    "            process_where(token, identifier_set)\n",
    "        elif isinstance(token, sqlparse.sql.Identifier):\n",
    "            process_identifier(token, identifier_set)\n",
    "    return list(identifier_set)\n",
    "\n",
    "query = \"select top 10 getdate(), order_number, client_name, sum(net_revenue) from orders o join revenue r on o.order_id = r.order_id where revenue_order in ('3245', '34244',  '4532')\"\n",
    "identifiers = get_identifiers(query)\n",
    "print(identifiers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"select top 10 getdate(), hzeuedhpnmuv, qimyvibgkze, sum(net_revenue) from lauwkt o join jjiurhy r on o.zggccmub = r.zggccmub where etuanvvjinxdc in ('3245', '34244',  '4532')\", {'order_number': 'hzeuedhpnmuv', 'revenue': 'jjiurhy', 'order_id': 'zggccmub', 'revenue_order': 'etuanvvjinxdc', 'orders': 'lauwkt', 'client_name': 'qimyvibgkze'})\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "def masking(identifiers, sql):\n",
    "    \"\"\"\n",
    "    This function takes in a list of identifiers and an SQL query as input, and replaces the identifiers in the SQL query with random words.\n",
    "    \"\"\"\n",
    "    # Create a dictionary to store the mapping between original identifiers and masked words\n",
    "    word_map = {}\n",
    "    \n",
    "    # Loop through each identifier in the list of identifiers\n",
    "    for identifier in identifiers:\n",
    "        # Generate a random word to replace the original identifier\n",
    "        random_word = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz', k=len(identifier)))\n",
    "        \n",
    "        # Add the mapping to the dictionary\n",
    "        word_map[identifier] = random_word\n",
    "        \n",
    "        # Replace the original identifier with the random word in the SQL string\n",
    "        sql = re.sub(r'\\b{}\\b'.format(identifier), random_word, sql)\n",
    "    \n",
    "    # Return the masked SQL string and the word map\n",
    "    return sql, word_map\n",
    "\n",
    "\n",
    "masked_sql_wordmap = masking(identifiers, query)\n",
    "print(masked_sql_wordmap)\n",
    "\n",
    "# Still missing the Where cluse pick up - I am missing revenue_order field. This needs to be added to identifiers function. Here I am then this is ready. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identifiers(sql):\n",
    "    parsed_tokens = sqlparse.parse(sql)[0]\n",
    "    identifier_set = set()\n",
    "\n",
    "    reserved_words = ['TOP', 'SELECT', 'FROM', 'WHERE', 'JOIN', 'LEFT', 'RIGHT', 'INNER', 'OUTER', 'ON', 'GROUP', 'BY', 'HAVING', 'ORDER', 'ASC', 'DESC']\n",
    "\n",
    "    def process_identifier(token, identifier_set):\n",
    "        identifier_name = token.get_real_name()\n",
    "        if '.' in identifier_name:\n",
    "            identifier_name = identifier_name.split('.')[1]\n",
    "        identifier_set.add(identifier_name)\n",
    "\n",
    "    def process_function_arguments(token, identifier_set):\n",
    "        if isinstance(token, sqlparse.sql.Identifier):\n",
    "            process_identifier(token, identifier_set)\n",
    "        elif isinstance(token, sqlparse.sql.IdentifierList):\n",
    "            for identifier in token.get_identifiers():\n",
    "                if isinstance(identifier, sqlparse.sql.Identifier):\n",
    "                    process_identifier(identifier, identifier_set)\n",
    "        elif isinstance(token, sqlparse.sql.Parenthesis):\n",
    "            for subtoken in token.tokens:\n",
    "                process_function_arguments(subtoken, identifier_set)\n",
    "\n",
    "    def add_identifiers_from_function(token, identifier_set):\n",
    "        for subtoken in token.tokens:\n",
    "            process_function_arguments(subtoken, identifier_set)\n",
    "\n",
    "    def process_where(token, identifier_set):\n",
    "        for subtoken in token.tokens:\n",
    "            if isinstance(subtoken, sqlparse.sql.Comparison):\n",
    "                process_identifier(subtoken.left, identifier_set)\n",
    "            elif isinstance(subtoken, sqlparse.sql.Identifier):\n",
    "                process_identifier(subtoken, identifier_set)\n",
    "\n",
    "    for token in parsed_tokens.tokens:\n",
    "        if isinstance(token, sqlparse.sql.Function):\n",
    "            add_identifiers_from_function(token, identifier_set)\n",
    "            continue\n",
    "        if token.value.upper() in reserved_words:\n",
    "            continue\n",
    "        if isinstance(token, sqlparse.sql.IdentifierList):\n",
    "            for identifier in token.get_identifiers():\n",
    "                if isinstance(identifier, sqlparse.sql.Identifier):\n",
    "                    process_identifier(identifier, identifier_set)\n",
    "        elif isinstance(token, sqlparse.sql.Comparison):\n",
    "            process_identifier(token.left, identifier_set)\n",
    "        elif isinstance(token, sqlparse.sql.Where):\n",
    "            process_where(token, identifier_set)\n",
    "        elif isinstance(token, sqlparse.sql.Identifier):\n",
    "            process_identifier(token, identifier_set)\n",
    "    return list(identifier_set)\n",
    "\n",
    "def sql_masking(identifiers, sql):\n",
    "    \"\"\"\n",
    "    This function takes in a list of identifiers and an SQL query as input, and replaces the identifiers in the SQL query with random words.\n",
    "    \"\"\"\n",
    "    # Create a dictionary to store the mapping between original identifiers and masked words\n",
    "    word_map = {}\n",
    "    \n",
    "    # Loop through each identifier in the list of identifiers\n",
    "    for identifier in identifiers:\n",
    "        # Generate a random word to replace the original identifier\n",
    "        random_word = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz', k=len(identifier)))\n",
    "        \n",
    "        # Add the mapping to the dictionary\n",
    "        word_map[identifier] = random_word\n",
    "        \n",
    "        # Replace the original identifier with the random word in the SQL string\n",
    "        sql = re.sub(r'\\b{}\\b'.format(identifier), random_word, sql)\n",
    "    \n",
    "    # Return the masked SQL string and the word map\n",
    "    return sql, word_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=\"select top 10 getdate(), order_number, client_name, sum(net_revenue) from orders o join revenue r on o.order_id = r.order_id where revenue_number in ('2345', '9908', '6671')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['order_number', 'revenue_number', 'revenue', 'order_id', 'orders', 'client_name']\n"
     ]
    }
   ],
   "source": [
    "list_of_fields = get_identifiers(sql)\n",
    "print(list_of_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select top 10 getdate(), rbkvnpvaqzio, ggdcjfoivjv, sum(net_revenue) from mmkuuz o join orekjeg r on o.hpdptrzn = r.hpdptrzn where xqpoososamybqd in ('2345', '9908', '6671')\n"
     ]
    }
   ],
   "source": [
    "masked_sql, word_map  = sql_masking(list_of_fields, sql)\n",
    "print(masked_sql)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_dialectify(to_sql, masked_sql):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": 'You are an expert SQL developer that is proficient in MS SQL Server, MySQL, Oracle, PostgreSQL, SQLite, Snowflake SQL dialects.'},\n",
    "            {\"role\": \"system\", \"content\": 'Only return the converted sql code and do not explain the conversion process.'},\n",
    "            {\"role\": \"system\", \"content\": 'Check for the correctness of the entered SQL code. And make updates if necessary. List the changes succinctly in the chat.'},\n",
    "            {\"role\": \"system\", \"content\": 'Let''s think step by step.'},\n",
    "            {\"role\": \"user\", \"content\": f'Detect the dialect of the following SQL code: \"{masked_sql}\"'},\n",
    "            {\"role\": \"system\", \"content\": f'Check and fix errors for the top common SQL syntax mistakes for the detected dialect. List updated parts of the following SQL code: \"{masked_sql}\"'},\n",
    "            {\"role\": \"user\", \"content\": f'Convert the updated SQL code from detected dialect to \"{to_sql}\": \"\\n\\n{masked_sql}\"'}\n",
    "        ]\n",
    "    )\n",
    "    converted_sql = completion.choices[0].message.content\n",
    "    return converted_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if openai.api_key and st.button(\"Convert\"):\n",
    "    st.write(\"Converting the SQL Code...\")\n",
    "    # Convert the SQL dialect using the OpenAI API\n",
    "    masked_converted_sql = sql_dialectify(to_sql, masked_sql)\n",
    "    # Display the converted SQL code\n",
    "    st.text_area(\"Converted SQL Code\", masked_converted_sql)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
