{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables: orders\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "from sqlparse.sql import IdentifierList, Identifier\n",
    "from sqlparse.tokens import Keyword, DML\n",
    "\n",
    "\n",
    "def is_subselect(parsed):\n",
    "    if not parsed.is_group:\n",
    "        return False\n",
    "    for item in parsed.tokens:\n",
    "        if item.ttype is DML and item.value.upper() == 'SELECT':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def extract_from_part(parsed):\n",
    "    from_seen = False\n",
    "    for item in parsed.tokens:\n",
    "        if from_seen:\n",
    "            if is_subselect(item):\n",
    "                yield from extract_from_part(item)\n",
    "            elif item.ttype is Keyword:\n",
    "                return\n",
    "            else:\n",
    "                yield item\n",
    "        elif item.ttype is Keyword and item.value.upper() == 'FROM':\n",
    "            from_seen = True\n",
    "\n",
    "\n",
    "def extract_table_identifiers(token_stream):\n",
    "    for item in token_stream:\n",
    "        if isinstance(item, IdentifierList):\n",
    "            for identifier in item.get_identifiers():\n",
    "                yield identifier.get_name()\n",
    "        elif isinstance(item, Identifier):\n",
    "            yield item.get_name()\n",
    "        # It's a bug to check for Keyword here, but in the example\n",
    "        # above some tables names are identified as keywords...\n",
    "        elif item.ttype is Keyword:\n",
    "            yield item.value\n",
    "\n",
    "\n",
    "def extract_tables(sql):\n",
    "    stream = extract_from_part(sqlparse.parse(sql)[0])\n",
    "    return list(extract_table_identifiers(stream))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sql = \"\"\"\n",
    "    select top 10 getdate(), order_number, client_name, sum(net_revenue) from orders join revenue r on o.order_id = r.order_id\n",
    "    \"\"\"\n",
    "\n",
    "    tables = ', '.join(extract_tables(sql))\n",
    "    print('Tables: {}'.format(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"select top 10 getdate(), order_number, client_name, sum(net_revenue) from orders o join revenue r on o.order_id = r.order_id\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: id           DEFINITION: integer primary key\n",
      "NAME: title        DEFINITION: varchar 200 not null\n",
      "NAME: description  DEFINITION: text\n"
     ]
    }
   ],
   "source": [
    "# Example for retrieving column definitions from a CREATE statement\n",
    "# using low-level functions.\n",
    "\n",
    "import sqlparse\n",
    "\n",
    "\n",
    "def extract_definitions(token_list):\n",
    "    # assumes that token_list is a parenthesis\n",
    "    definitions = []\n",
    "    tmp = []\n",
    "    par_level = 0\n",
    "    for token in token_list.flatten():\n",
    "        if token.is_whitespace:\n",
    "            continue\n",
    "        elif token.match(sqlparse.tokens.Punctuation, '('):\n",
    "            par_level += 1\n",
    "            continue\n",
    "        if token.match(sqlparse.tokens.Punctuation, ')'):\n",
    "            if par_level == 0:\n",
    "                break\n",
    "            else:\n",
    "                par_level += 1\n",
    "        elif token.match(sqlparse.tokens.Punctuation, ','):\n",
    "            if tmp:\n",
    "                definitions.append(tmp)\n",
    "            tmp = []\n",
    "        else:\n",
    "            tmp.append(token)\n",
    "    if tmp:\n",
    "        definitions.append(tmp)\n",
    "    return definitions\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    SQL = \"\"\"CREATE TABLE foo (\n",
    "             id integer primary key,\n",
    "             title varchar(200) not null,\n",
    "             description text);\"\"\"\n",
    "\n",
    "    parsed = sqlparse.parse(SQL)[0]\n",
    "\n",
    "    # extract the parenthesis which holds column definitions\n",
    "    _, par = parsed.token_next_by(i=sqlparse.sql.Parenthesis)\n",
    "    columns = extract_definitions(par)\n",
    "\n",
    "    for column in columns:\n",
    "        print('NAME: {name!s:12} DEFINITION: {definition}'.format(\n",
    "            name=column[0], definition=' '.join(str(t) for t in column[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlparse\n",
    "\n",
    "def get_identifiers(query):\n",
    "    parsed_tokens = sqlparse.parse(query)[0]\n",
    "    identifier_set = set()\n",
    "    for token in parsed_tokens.tokens:\n",
    "        if isinstance(token, sqlparse.sql.IdentifierList):\n",
    "            for identifier in token.get_identifiers():\n",
    "                identifier_name = identifier.get_real_name()\n",
    "                if '.' in identifier_name:\n",
    "                    identifier_name = identifier_name.split('.')[1]\n",
    "                identifier_set.add(identifier_name)\n",
    "        # If the token is an identifier, add it to the set\n",
    "        elif isinstance(token, sqlparse.sql.Identifier):\n",
    "            identifier_name = token.get_real_name()\n",
    "            if '.' in identifier_name:\n",
    "                identifier_name = identifier_name.split('.')[1]\n",
    "            identifier_set.add(identifier_name)\n",
    "        # If the token is a comparison operator, get the column name\n",
    "        elif isinstance(token, sqlparse.sql.Comparison):\n",
    "            identifier_name = token.left.get_real_name()\n",
    "            if '.' in identifier_name:\n",
    "                identifier_name = identifier_name.split('.')[1]\n",
    "            identifier_set.add(identifier_name)\n",
    "        # If the token is a column, add it to the set\n",
    "        elif isinstance(token, sqlparse.sql.Function):\n",
    "            for sub_token in token.tokens:\n",
    "                if isinstance(sub_token, sqlparse.sql.Identifier):\n",
    "                    identifier_name = sub_token.get_real_name()\n",
    "                    if '.' in identifier_name:\n",
    "                        identifier_name = identifier_name.split('.')[1]\n",
    "                    identifier_set.add(identifier_name)\n",
    "    return list(identifier_set)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OMG finally works. A bit specific to the query though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlparse\n",
    "\n",
    "def get_identifiers(query):\n",
    "    parsed_tokens = sqlparse.parse(query)[0]\n",
    "    identifier_set = set()\n",
    "    \n",
    "    reserved_words = ['TOP', 'SELECT', 'FROM', 'WHERE', 'JOIN', 'LEFT', 'RIGHT', 'INNER', 'OUTER', 'ON', 'GROUP', 'BY', 'HAVING', 'ORDER', 'ASC', 'DESC']\n",
    "\n",
    "    for token in parsed_tokens.tokens:\n",
    "        # If the token is a function, skip it\n",
    "        if isinstance(token, sqlparse.sql.Function) or token.value.upper() in reserved_words:\n",
    "            continue\n",
    "        if isinstance(token, sqlparse.sql.Function):\n",
    "            continue\n",
    "        if isinstance(token, sqlparse.sql.IdentifierList):\n",
    "            for identifier in token.get_identifiers():\n",
    "                if isinstance(identifier, sqlparse.sql.Identifier):\n",
    "                    identifier_name = identifier.get_real_name()\n",
    "                    if '.' in identifier_name:\n",
    "                        identifier_name = identifier_name.split('.')[1]\n",
    "                    identifier_set.add(identifier_name)\n",
    "        # If the token is a comparison operator, get the column name\n",
    "        elif isinstance(token, sqlparse.sql.Comparison):\n",
    "            identifier_name = token.left.get_real_name()\n",
    "            if '.' in identifier_name:\n",
    "                identifier_name = identifier_name.split('.')[1]\n",
    "            identifier_set.add(identifier_name)\n",
    "        elif isinstance(token, sqlparse.sql.Identifier):\n",
    "            identifier_name = token.get_real_name()\n",
    "            if '.' in identifier_name:\n",
    "                identifier_name = identifier_name.split('.')[1]\n",
    "            identifier_set.add(identifier_name)\n",
    "    return list(identifier_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['revenue', 'order_id', 'orders', 'client_name', 'order_number']\n"
     ]
    }
   ],
   "source": [
    "query =\"select top 10 getdate(), order_number, client_name, sum(net_revenue) from orders o join revenue r on o.order_id = r.order_id\"\n",
    "print(get_identifiers(query))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
